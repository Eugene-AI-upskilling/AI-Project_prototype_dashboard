# coding=utf-8
"""
í˜ì´ì§€ 2: DART ì ì •ì‹¤ì  - ì›¹ì—ì„œ ì§ì ‘ ìˆ˜ì§‘
"""

import streamlit as st
import pandas as pd
import os
import sys
import re
import time
from datetime import datetime
from typing import Optional, List, Dict, Any
from io import StringIO, BytesIO

import requests
from bs4 import BeautifulSoup

# í”„ë¡œì íŠ¸ ê²½ë¡œ
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

st.set_page_config(page_title="DART ì ì •ì‹¤ì ", page_icon="ğŸ“ˆ", layout="wide")

# =============================================================================
# KIND í¬ë¡¤ë§ í•¨ìˆ˜ë“¤
# =============================================================================

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
}

KIND_TODAY_URL = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"
KIND_VIEWER_URL = "https://kind.krx.co.kr/common/disclsviewer.do"


def search_prelim_earnings(search_date: str, progress_callback=None) -> List[Dict]:
    """KINDì—ì„œ ì ì •ì‹¤ì  ê³µì‹œ ê²€ìƒ‰"""
    headers = HEADERS.copy()
    headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=UTF-8'
    headers['X-Requested-With'] = 'XMLHttpRequest'

    disclosures = []
    page = 1

    while page <= 5:
        data = {
            'method': 'searchTodayDisclosureSub',
            'currentPageSize': '500',
            'pageIndex': str(page),
            'orderMode': '0',
            'orderStat': 'D',
            'forward': 'todaydisclosure_sub',
            'marketType': '',
            'disclosureType': '',
            'fromDate': search_date,
            'toDate': search_date
        }

        try:
            response = requests.post(KIND_TODAY_URL, headers=headers, data=data, timeout=30)
            soup = BeautifulSoup(response.text, 'html.parser')
            rows = soup.select('tbody tr')

            if len(rows) == 0:
                break

            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 4:
                    continue

                title_elem = cols[2].find('a')
                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True)

                if 'ì ì •' not in title:
                    continue

                onclick = title_elem.get('onclick', '')
                acptno_match = re.search(r"openDisclsViewer\('(\d+)'", onclick)
                if not acptno_match:
                    continue

                acptno = acptno_match.group(1)

                if any(d['acptno'] == acptno for d in disclosures):
                    continue

                company_elem = cols[1].find('a', id='companysum')
                corp_name = company_elem.get_text(strip=True) if company_elem else ''

                corp_onclick = company_elem.get('onclick', '') if company_elem else ''
                code_match = re.search(r"companysummary_open\('(\d+)'", corp_onclick)
                stock_code = code_match.group(1).zfill(6) if code_match else ''

                time_str = cols[0].get_text(strip=True)

                disclosures.append({
                    'time': time_str,
                    'stock_code': stock_code,
                    'corp_name': corp_name,
                    'title': title,
                    'acptno': acptno,
                    'date': search_date
                })

            if len(rows) < 500:
                break

            page += 1
            time.sleep(0.3)

        except Exception as e:
            st.warning(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            break

    return disclosures


def get_disclosure_document(acptno: str) -> Optional[str]:
    """KIND ê³µì‹œ ë³¸ë¬¸ HTML ê°€ì ¸ì˜¤ê¸°"""
    try:
        viewer_url = f"{KIND_VIEWER_URL}?method=search&acptno={acptno}"
        response = requests.get(viewer_url, headers=HEADERS, timeout=30)

        soup = BeautifulSoup(response.text, 'html.parser')
        select = soup.find('select', id='mainDoc')
        if not select:
            return None

        docNo = None
        for opt in select.find_all('option'):
            val = opt.get('value', '')
            if '|' in val:
                docNo = val.split('|')[0]
                break

        if not docNo:
            return None

        post_data = {'method': 'searchContents', 'docNo': docNo}
        post_headers = HEADERS.copy()
        post_headers['Content-Type'] = 'application/x-www-form-urlencoded'

        post_response = requests.post(KIND_VIEWER_URL, data=post_data, headers=post_headers, timeout=30)

        url_match = re.search(r"setPath\s*\([^,]*,\s*['\"]([^'\"]+)['\"]", post_response.text)
        if not url_match:
            return None

        doc_url = url_match.group(1)
        if not doc_url.startswith('http'):
            doc_url = 'https://kind.krx.co.kr' + doc_url

        doc_response = requests.get(doc_url, headers=HEADERS, timeout=30)

        try:
            return doc_response.content.decode('utf-8')
        except:
            try:
                return doc_response.content.decode('euc-kr')
            except:
                return doc_response.content.decode('cp949', errors='ignore')

    except Exception as e:
        return None


def extract_earnings_table(html_content: str) -> Optional[pd.DataFrame]:
    """HTMLì—ì„œ ì‹¤ì  í…Œì´ë¸” ì¶”ì¶œ"""
    if not html_content:
        return None

    try:
        tables = pd.read_html(StringIO(html_content))
    except:
        return None

    if not tables:
        return None

    best_table = None
    best_score = 0

    for df in tables:
        if df.empty:
            continue

        df_str = df.to_string()
        score = 0

        if 'ë§¤ì¶œì•¡' in df_str:
            score += 10
        if 'ì˜ì—…ì´ìµ' in df_str:
            score += 10
        if 'ë‹¹ê¸°ìˆœì´ìµ' in df_str:
            score += 10
        if 'ë‹¹ê¸°' in df_str or 'ë‹¹í•´' in df_str:
            score += 5
        if 3 <= len(df) <= 30 and 3 <= len(df.columns) <= 15:
            score += 5

        if score > best_score:
            best_score = score
            best_table = df

    return best_table


# =============================================================================
# ë©”ì¸ ì•±
# =============================================================================

def main():
    st.title("ğŸ“ˆ DART ì ì •ì‹¤ì  ê³µì‹œ")
    st.markdown("KINDì—ì„œ ì ì •ì‹¤ì  ê³µì‹œ ìˆ˜ì§‘ â†’ ì •ê·œí™” â†’ ì¡°íšŒ")

    st.markdown("---")

    # ì„¤ì •
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ“… ì¡°íšŒ ì„¤ì •")
        target_date = st.date_input(
            "ì¡°íšŒ ë‚ ì§œ",
            value=datetime.now().date()
        )
        date_str = target_date.strftime('%Y%m%d')

    with col2:
        st.subheader("ğŸ“Š í˜„í™©")
        st.info(f"ì„ íƒëœ ë‚ ì§œ: **{target_date.strftime('%Yë…„ %mì›” %dì¼')}**")

    st.markdown("---")

    # ìˆ˜ì§‘ ë²„íŠ¼
    if st.button("ğŸ” ì ì •ì‹¤ì  ì¡°íšŒ", type="primary", use_container_width=True):

        # 1ë‹¨ê³„: ê³µì‹œ ê²€ìƒ‰
        with st.spinner("KINDì—ì„œ ê³µì‹œ ê²€ìƒ‰ ì¤‘..."):
            disclosures = search_prelim_earnings(date_str)

        if not disclosures:
            st.warning(f"âš ï¸ {target_date.strftime('%Y-%m-%d')}ì— ì ì •ì‹¤ì  ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        st.success(f"âœ… {len(disclosures)}ê±´ì˜ ì ì •ì‹¤ì  ê³µì‹œ ë°œê²¬")

        # 2ë‹¨ê³„: ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
        progress_bar = st.progress(0)
        status_text = st.empty()

        results = []

        for i, disc in enumerate(disclosures):
            status_text.text(f"ìˆ˜ì§‘ ì¤‘: {disc['corp_name']} ({i+1}/{len(disclosures)})")
            progress_bar.progress((i + 1) / len(disclosures))

            try:
                html = get_disclosure_document(disc['acptno'])
                if html:
                    table = extract_earnings_table(html)
                    if table is not None and not table.empty:
                        results.append({
                            'corp_name': disc['corp_name'],
                            'stock_code': disc['stock_code'],
                            'title': disc['title'],
                            'time': disc['time'],
                            'acptno': disc['acptno'],
                            'table': table
                        })

                time.sleep(0.3)

            except Exception as e:
                pass

        progress_bar.progress(1.0)
        status_text.text("ì™„ë£Œ!")

        # ê²°ê³¼ ì €ì¥
        st.session_state['dart_results'] = results
        st.session_state['dart_date'] = date_str

        st.success(f"âœ… {len(results)}ê°œ ê¸°ì—… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")

    # ê²°ê³¼ í‘œì‹œ
    if 'dart_results' in st.session_state and st.session_state['dart_results']:
        results = st.session_state['dart_results']

        st.markdown("---")
        st.subheader(f"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ({len(results)}ê°œ ê¸°ì—…)")

        # ê²€ìƒ‰ í•„í„°
        col1, col2 = st.columns(2)

        with col1:
            search_text = st.text_input(
                "ğŸ” ì¢…ëª©ì½”ë“œ ë˜ëŠ” ê¸°ì—…ëª… ê²€ìƒ‰",
                placeholder="ì˜ˆ: 005930 ë˜ëŠ” ì‚¼ì„±ì „ì"
            )

        with col2:
            corp_names = ["ì „ì²´ ë³´ê¸°"] + [r['corp_name'] for r in results]
            selected_corp = st.selectbox("ğŸ“‹ ê¸°ì—… ì„ íƒ", corp_names)

        # í•„í„°ë§
        if search_text:
            # ê²€ìƒ‰ì–´ë¡œ í•„í„°ë§
            search_text = search_text.strip()
            filtered_results = [
                r for r in results
                if search_text.lower() in r['corp_name'].lower()
                or search_text in r['stock_code']
            ]

            if not filtered_results:
                st.warning(f"'{search_text}'ì— í•´ë‹¹í•˜ëŠ” ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(filtered_results)}ê°œ ê¸°ì—…")

                for r in filtered_results:
                    with st.expander(f"**{r['corp_name']}** ({r['stock_code']}) - {r['time']}"):
                        st.caption(f"ê³µì‹œ: {r['title']}")
                        st.dataframe(r['table'], use_container_width=True)

        elif selected_corp == "ì „ì²´ ë³´ê¸°":
            # ìš”ì•½ í…Œì´ë¸”
            summary_data = []
            for r in results:
                summary_data.append({
                    'ì‹œê°„': r['time'],
                    'ì¢…ëª©ì½”ë“œ': r['stock_code'],
                    'ê¸°ì—…ëª…': r['corp_name'],
                    'ê³µì‹œì œëª©': r['title'][:40] + "..." if len(r['title']) > 40 else r['title']
                })

            st.dataframe(pd.DataFrame(summary_data), use_container_width=True)

        else:
            # ê°œë³„ ê¸°ì—… ìƒì„¸
            for r in results:
                if r['corp_name'] == selected_corp:
                    st.markdown(f"### {r['corp_name']} ({r['stock_code']})")
                    st.caption(f"ê³µì‹œ: {r['title']}")
                    st.dataframe(r['table'], use_container_width=True)
                    break

        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
        st.markdown("---")

        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            summary_df = pd.DataFrame([{
                'ì‹œê°„': r['time'],
                'ì¢…ëª©ì½”ë“œ': r['stock_code'],
                'ê¸°ì—…ëª…': r['corp_name'],
                'ê³µì‹œì œëª©': r['title']
            } for r in results])
            summary_df.to_excel(writer, sheet_name='ìš”ì•½', index=False)

            for r in results[:20]:
                sheet_name = r['corp_name'][:31].replace('/', '_')
                r['table'].to_excel(writer, sheet_name=sheet_name, index=False)

        output.seek(0)

        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=output,
            file_name=f"prelim_earnings_{st.session_state.get('dart_date', date_str)}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    st.markdown("---")

    # CLI ì•ˆë‚´
    with st.expander("ğŸ’» ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ë¡œì»¬ PCì—ì„œ ì‹¤í–‰)"):
        st.markdown("""
        **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**ì€ ì›¹ ëŒ€ì‹œë³´ë“œê°€ ì•„ë‹Œ **ë¡œì»¬ PC**ì—ì„œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

        ### ì‹¤í–‰ ë°©ë²•

        1. **ëª…ë ¹ í”„ë¡¬í”„íŠ¸(CMD) ë˜ëŠ” PowerShell ì—´ê¸°**
           - Windows: `Win + R` â†’ `cmd` ì…ë ¥ â†’ Enter

        2. **í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™**
        ```
        cd C:\\Users\\anjs9\\OneDrive\\ë°”íƒ• í™”ë©´\\Eugene_AI_Project
        ```

        3. **ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**
        ```
        # íŠ¹ì • ë‚ ì§œ ì¡°íšŒ
        python scripts/2_DART_Prelim_Earnings.py --date=20260209

        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (5ë¶„ ê°„ê²©)
        python scripts/2_DART_Prelim_Earnings.py --monitor --interval=5

        # í…”ë ˆê·¸ë¨ ì•Œë¦¼ í¬í•¨
        python scripts/2_DART_Prelim_Earnings.py --monitor --telegram
        ```

        4. **ë˜ëŠ” ë°°ì¹˜ íŒŒì¼ ë”ë¸”í´ë¦­**
           - `run_prelim_monitor.bat` íŒŒì¼ ë”ë¸”í´ë¦­
        """)


if __name__ == "__main__":
    main()
